{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge-ATO-Outputs.py\n",
    "\n",
    "This script demonstrates how to merge Access to Opportunities (ATO) tables from multiple years into one table. It also formats the columns to match the schema of the table at:\n",
    "\n",
    "https://data.wfrc.org/datasets/access-to-opportunities-work-related-taz-based?geometry=-117.122%2C40.025%2C-106.669%2C41.481"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from simpledbf import Dbf5\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build paths to .dbf tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store highest common directory path\n",
    "scenarios = os.path.join(os.getcwd(), r'TDM\\0 - ModelDev\\Official Release\\v8.3.1\\WF TDM v8.3.1 - 2020-05-08\\Scenarios')\n",
    "\n",
    "# Store path to 2019\n",
    "path_2019 = os.path.join(scenarios, r'BY_2019\\7_PostProcessing\\Access_to_Opportunity_2019.dbf')\n",
    "print(path_2019 + '\\n')\n",
    "\n",
    "# Store path to 2030\n",
    "path_2030 = os.path.join(scenarios, r'Need_2030\\7_PostProcessing\\Access_to_Opportunity_2030.dbf')\n",
    "print(path_2030 + '\\n')\n",
    "\n",
    "# Store path to 2040\n",
    "path_2040 = os.path.join(scenarios, r'Need_2040\\7_PostProcessing\\Access_to_Opportunity_2040.dbf')\n",
    "print(path_2040 + '\\n')\n",
    "\n",
    "# Store path to 2050\n",
    "path_2050 = os.path.join(scenarios, r'Need_2050\\7_PostProcessing\\Access_to_Opportunity_2050.dbf')\n",
    "print(path_2050 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dbf tables into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in 2019 as dbf5 object\n",
    "dbf_2019 = Dbf5(path_2019)\n",
    "\n",
    "# Read 2019 dbf5 as pandas dataframe object\n",
    "df_2019 = dbf_2019.to_dataframe()\n",
    "\n",
    "# 2030\n",
    "dbf_2030 = Dbf5(path_2030)\n",
    "df_2030 = dbf_2030.to_dataframe()\n",
    "\n",
    "# 2040\n",
    "dbf_2040 = Dbf5(path_2040)\n",
    "df_2040 = dbf_2040.to_dataframe()\n",
    "\n",
    "# 2050\n",
    "dbf_2050 = Dbf5(path_2050)\n",
    "df_2050 = dbf_2050.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview tables (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 5 rows of a table\n",
    "print(df_2019.head())\n",
    "print()\n",
    "\n",
    "# Show number of rows and columns\n",
    "print(df_2019.shape)\n",
    "print()\n",
    "\n",
    "# Show column names\n",
    "print(list(df_2019.columns))\n",
    "print()\n",
    "print(list(df_2030.columns))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepping and Formatting tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base table\n",
    "base_table = df_2019[['TAZID', 'CO_TAZID', 'DEVACRES']].copy()\n",
    "\n",
    "# Desired columns to subset by \n",
    "columns = ['CO_TAZID', 'HH', 'JOB', 'AUTO_JB', 'AUTO_HH', 'TRAN_JB', 'TRAN_HH', \\\n",
    "           'COMP_AUTO', 'COMP_TRAN']\n",
    "\n",
    "# subset tables to desired columns\n",
    "df_2019_subset = df_2019[columns].copy()\n",
    "df_2030_subset = df_2030[columns].copy()\n",
    "df_2040_subset = df_2040[columns].copy()\n",
    "df_2050_subset = df_2050[columns].copy()\n",
    "\n",
    "# Show Column names before conversion\n",
    "print(\"ATO 2040 Column names (BEFORE):\")\n",
    "print(list(df_2040_subset.columns))\n",
    "print()\n",
    "\n",
    "# Rename columns, concatenating year to the end\n",
    "df_2019_subset.columns = ['CO_TAZID', 'HH_19', 'JOB_19', 'JOBAUTO_19', 'HHAUTO_19', 'JOBTRANSIT_19', 'HHTRANSIT_19', \\\n",
    "           'COMPAUTO_19', 'COMPTRANSIT_19']\n",
    "\n",
    "df_2030_subset.columns = ['CO_TAZID', 'HH_30', 'JOB_30', 'JOBAUTO_30', 'HHAUTO_30', 'JOBTRANSIT_30', 'HHTRANSIT_30', \\\n",
    "           'COMPAUTO_30', 'COMPTRANSIT_30']\n",
    "\n",
    "df_2040_subset.columns = ['CO_TAZID', 'HH_40', 'JOB_40', 'JOBAUTO_40', 'HHAUTO_40', 'JOBTRANSIT_40', 'HHTRANSIT_40', \\\n",
    "           'COMPAUTO_40', 'COMPTRANSIT_40']\n",
    "\n",
    "df_2050_subset.columns = ['CO_TAZID', 'HH_50', 'JOB_50', 'JOBAUTO_50', 'HHAUTO_50', 'JOBTRANSIT_50', 'HHTRANSIT_50', \\\n",
    "           'COMPAUTO_50', 'COMPTRANSIT_50']\n",
    "\n",
    "# Show Column names after conversion\n",
    "print(\"ATO 2040 Column names (AFTER):\")\n",
    "print(list(df_2040_subset.columns))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join the tables (Method #1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tables to the base table using CO_TAZID field\n",
    "ato_table = base_table\n",
    "\n",
    "ato_table = ato_table.merge(df_2019_subset, left_on = 'CO_TAZID', right_on = 'CO_TAZID' , how = 'inner')\n",
    "ato_table = ato_table.merge(df_2030_subset, left_on = 'CO_TAZID', right_on = 'CO_TAZID' , how = 'inner')\n",
    "ato_table = ato_table.merge(df_2040_subset, left_on = 'CO_TAZID', right_on = 'CO_TAZID' , how = 'inner')\n",
    "ato_table = ato_table.merge(df_2050_subset, left_on = 'CO_TAZID', right_on = 'CO_TAZID' , how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join the tables (Method #2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store ATO by year into list\n",
    "tables = [df_2019_subset, df_2030_subset, df_2040_subset, df_2050_subset]\n",
    "\n",
    "# Use loop to join each year table to the base table using CO_TAZID field\n",
    "ato_table = base_table\n",
    "for table in tables:\n",
    "    ato_table = ato_table.merge(table, left_on = 'CO_TAZID', right_on = 'CO_TAZID' , how = 'inner')\n",
    "\n",
    "# Show first 5 rows of merged table\n",
    "print(ato_table.head())\n",
    "print()\n",
    "\n",
    "print(ato_table.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store output folder path. There is a hidden .gitignore file here so files written won't be pushed to github\n",
    "temp = os.path.join(os.getcwd(), 'Results')\n",
    "\n",
    "# Create name for output csv\n",
    "out_table = os.path.join(temp, 'ATO.csv')\n",
    "\n",
    "# export data frame to csv\n",
    "ato_table.to_csv(out_table, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final step would be joining the output table to a TAZ shapefile/feature dataset using ArcGIS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
