{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge-ATO-Outputs.py\n",
    "\n",
    "This script demonstrates how to merge Access to Opportunities (ATO) tables from multiple years into one table. It also formats the columns to match the schema of the table at:\n",
    "\n",
    "https://data.wfrc.org/datasets/access-to-opportunities-work-related-taz-based?geometry=-117.122%2C40.025%2C-106.669%2C41.481"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from simpledbf import Dbf5\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build paths to .dbf tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Projects\\Merge-ATO-Outputs\\TDM\\0 - ModelDev\\Official Release\\v8.3.1\\WF TDM v8.3.1 - 2020-05-08\\Scenarios\\BY_2019\\7_PostProcessing\\Access_to_Opportunity_2019.dbf\n",
      "\n",
      "E:\\Projects\\Merge-ATO-Outputs\\TDM\\0 - ModelDev\\Official Release\\v8.3.1\\WF TDM v8.3.1 - 2020-05-08\\Scenarios\\Need_2030\\7_PostProcessing\\Access_to_Opportunity_2030.dbf\n",
      "\n",
      "E:\\Projects\\Merge-ATO-Outputs\\TDM\\0 - ModelDev\\Official Release\\v8.3.1\\WF TDM v8.3.1 - 2020-05-08\\Scenarios\\Need_2040\\7_PostProcessing\\Access_to_Opportunity_2040.dbf\n",
      "\n",
      "E:\\Projects\\Merge-ATO-Outputs\\TDM\\0 - ModelDev\\Official Release\\v8.3.1\\WF TDM v8.3.1 - 2020-05-08\\Scenarios\\Need_2050\\7_PostProcessing\\Access_to_Opportunity_2050.dbf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store highest common directory path\n",
    "scenarios = os.path.join(os.getcwd(), r'TDM\\0 - ModelDev\\Official Release\\v8.3.1\\WF TDM v8.3.1 - 2020-05-08\\Scenarios')\n",
    "\n",
    "# Store path to 2019\n",
    "path_2019 = os.path.join(scenarios, r'BY_2019\\7_PostProcessing\\Access_to_Opportunity_2019.dbf')\n",
    "print(path_2019 + '\\n')\n",
    "\n",
    "# Store path to 2030\n",
    "path_2030 = os.path.join(scenarios, r'Need_2030\\7_PostProcessing\\Access_to_Opportunity_2030.dbf')\n",
    "print(path_2030 + '\\n')\n",
    "\n",
    "# Store path to 2040\n",
    "path_2040 = os.path.join(scenarios, r'Need_2040\\7_PostProcessing\\Access_to_Opportunity_2040.dbf')\n",
    "print(path_2040 + '\\n')\n",
    "\n",
    "# Store path to 2050\n",
    "path_2050 = os.path.join(scenarios, r'Need_2050\\7_PostProcessing\\Access_to_Opportunity_2050.dbf')\n",
    "print(path_2050 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dbf tables into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in 2019 as dbf5 object\n",
    "dbf_2019 = Dbf5(path_2019)\n",
    "\n",
    "# Read 2019 dbf5 as pandas dataframe object\n",
    "df_2019 = dbf_2019.to_dataframe()\n",
    "\n",
    "# 2030\n",
    "dbf_2030 = Dbf5(path_2030)\n",
    "df_2030 = dbf_2030.to_dataframe()\n",
    "\n",
    "# 2040\n",
    "dbf_2040 = Dbf5(path_2040)\n",
    "df_2040 = dbf_2040.to_dataframe()\n",
    "\n",
    "# 2050\n",
    "dbf_2050 = Dbf5(path_2050)\n",
    "df_2050 = dbf_2050.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview tables (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TAZID  CO_TAZID  DEVACRES    HH   JOB  AUTO_JB  AUTO_HH  TRAN_JB  TRAN_HH  \\\n",
      "0      1     30001    374.61   1.1   0.0    30077    20324        0        0   \n",
      "1      2     30002    638.02  15.2   3.6    32960    22318        0        0   \n",
      "2      3     30003    470.79   5.1   2.6    33930    22989        0        0   \n",
      "3      4     30004    779.84  21.0  24.1    33229    22504        0        0   \n",
      "4      5     30005    395.38  30.5  69.5    41843    28507        0        0   \n",
      "\n",
      "   COMP_AUTO  COMP_TRAN  AUTO_JB_WT  AUTO_HH_WT  TRAN_JB_WT  TRAN_HH_WT  \n",
      "0      30077          0       33085           0           0           0  \n",
      "1      31728          0      500993       80346           0           0  \n",
      "2      31525          0      173044       59772           0           0  \n",
      "3      29066          0      697807      542343           0           0  \n",
      "4      34409          0     1276226     1981242           0           0  \n",
      "\n",
      "(2881, 15)\n",
      "\n",
      "['TAZID', 'CO_TAZID', 'DEVACRES', 'HH', 'JOB', 'AUTO_JB', 'AUTO_HH', 'TRAN_JB', 'TRAN_HH', 'COMP_AUTO', 'COMP_TRAN', 'AUTO_JB_WT', 'AUTO_HH_WT', 'TRAN_JB_WT', 'TRAN_HH_WT']\n",
      "\n",
      "['TAZID', 'CO_TAZID', 'DEVACRES', 'HH', 'JOB', 'AUTO_JB', 'AUTO_HH', 'TRAN_JB', 'TRAN_HH', 'COMP_AUTO', 'COMP_TRAN', 'AUTO_JB_WT', 'AUTO_HH_WT', 'TRAN_JB_WT', 'TRAN_HH_WT']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the first 5 rows of a table\n",
    "print(df_2019.head())\n",
    "print()\n",
    "\n",
    "# Show number of rows and columns\n",
    "print(df_2019.shape)\n",
    "print()\n",
    "\n",
    "# Show column names\n",
    "print(list(df_2019.columns))\n",
    "print()\n",
    "print(list(df_2030.columns))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepping and Formatting tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATO 2040 Column names (BEFORE):\n",
      "['CO_TAZID', 'HH', 'JOB', 'AUTO_JB', 'AUTO_HH', 'TRAN_JB', 'TRAN_HH', 'COMP_AUTO', 'COMP_TRAN']\n",
      "\n",
      "ATO 2040 Column names (AFTER):\n",
      "['CO_TAZID', 'HH_40', 'JOB_40', 'JOBAUTO_40', 'HHAUTO_40', 'JOBTRANSIT_40', 'HHTRANSIT_40', 'COMPAUTO_40', 'COMPTRANSIT_40']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the base table\n",
    "base_table = df_2019[['TAZID', 'CO_TAZID', 'DEVACRES']].copy()\n",
    "\n",
    "# Desired columns to subset by \n",
    "columns = ['CO_TAZID', 'HH', 'JOB', 'AUTO_JB', 'AUTO_HH', 'TRAN_JB', 'TRAN_HH', \\\n",
    "           'COMP_AUTO', 'COMP_TRAN']\n",
    "\n",
    "# subset tables to desired columns\n",
    "df_2019_subset = df_2019[columns].copy()\n",
    "df_2030_subset = df_2030[columns].copy()\n",
    "df_2040_subset = df_2040[columns].copy()\n",
    "df_2050_subset = df_2050[columns].copy()\n",
    "\n",
    "# Show Column names before conversion\n",
    "print(\"ATO 2040 Column names (BEFORE):\")\n",
    "print(list(df_2040_subset.columns))\n",
    "print()\n",
    "\n",
    "# Rename columns, concatenating year to the end\n",
    "df_2019_subset.columns = ['CO_TAZID', 'HH_19', 'JOB_19', 'JOBAUTO_19', 'HHAUTO_19', 'JOBTRANSIT_19', 'HHTRANSIT_19', \\\n",
    "           'COMPAUTO_19', 'COMPTRANSIT_19']\n",
    "\n",
    "df_2030_subset.columns = ['CO_TAZID', 'HH_30', 'JOB_30', 'JOBAUTO_30', 'HHAUTO_30', 'JOBTRANSIT_30', 'HHTRANSIT_30', \\\n",
    "           'COMPAUTO_30', 'COMPTRANSIT_30']\n",
    "\n",
    "df_2040_subset.columns = ['CO_TAZID', 'HH_40', 'JOB_40', 'JOBAUTO_40', 'HHAUTO_40', 'JOBTRANSIT_40', 'HHTRANSIT_40', \\\n",
    "           'COMPAUTO_40', 'COMPTRANSIT_40']\n",
    "\n",
    "df_2050_subset.columns = ['CO_TAZID', 'HH_50', 'JOB_50', 'JOBAUTO_50', 'HHAUTO_50', 'JOBTRANSIT_50', 'HHTRANSIT_50', \\\n",
    "           'COMPAUTO_50', 'COMPTRANSIT_50']\n",
    "\n",
    "# Show Column names after conversion\n",
    "print(\"ATO 2040 Column names (AFTER):\")\n",
    "print(list(df_2040_subset.columns))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join the tables (Method #1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tables to the base table using CO_TAZID field\n",
    "ato_table = base_table\n",
    "\n",
    "ato_table = ato_table.merge(df_2019_subset, left_on = 'CO_TAZID', right_on = 'CO_TAZID' , how = 'inner')\n",
    "ato_table = ato_table.merge(df_2030_subset, left_on = 'CO_TAZID', right_on = 'CO_TAZID' , how = 'inner')\n",
    "ato_table = ato_table.merge(df_2040_subset, left_on = 'CO_TAZID', right_on = 'CO_TAZID' , how = 'inner')\n",
    "ato_table = ato_table.merge(df_2050_subset, left_on = 'CO_TAZID', right_on = 'CO_TAZID' , how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join the tables (Method #2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TAZID  CO_TAZID  DEVACRES  HH_19  JOB_19  JOBAUTO_19  HHAUTO_19  \\\n",
      "0      1     30001    374.61    1.1     0.0       30077      20324   \n",
      "1      2     30002    638.02   15.2     3.6       32960      22318   \n",
      "2      3     30003    470.79    5.1     2.6       33930      22989   \n",
      "3      4     30004    779.84   21.0    24.1       33229      22504   \n",
      "4      5     30005    395.38   30.5    69.5       41843      28507   \n",
      "\n",
      "   JOBTRANSIT_19  HHTRANSIT_19  COMPAUTO_19  ...  COMPAUTO_40  COMPTRANSIT_40  \\\n",
      "0              0             0        30077  ...        36928               0   \n",
      "1              0             0        31728  ...        39370               0   \n",
      "2              0             0        31525  ...        39550               0   \n",
      "3              0             0        29066  ...        36594               0   \n",
      "4              0             0        34409  ...        44617               0   \n",
      "\n",
      "   HH_50  JOB_50  JOBAUTO_50  HHAUTO_50  JOBTRANSIT_50  HHTRANSIT_50  \\\n",
      "0    2.8     0.0       36346      28902              0             0   \n",
      "1   16.7     3.6       39895      31760              0             0   \n",
      "2    6.6     2.6       41088      32720              0             0   \n",
      "3   21.0    34.4       40229      32026              0             0   \n",
      "4   34.8    73.1       50882      40623              0             0   \n",
      "\n",
      "   COMPAUTO_50  COMPTRANSIT_50  \n",
      "0        36346               0  \n",
      "1        38950               0  \n",
      "2        39468               0  \n",
      "3        36130               0  \n",
      "4        45122               0  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "(2881, 35)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store ATO by year into list\n",
    "tables = [df_2019_subset, df_2030_subset, df_2040_subset, df_2050_subset]\n",
    "\n",
    "# Use loop to join each year table to the base table using CO_TAZID field\n",
    "ato_table = base_table\n",
    "\n",
    "for table in tables:\n",
    "    ato_table = ato_table.merge(table, left_on = 'CO_TAZID', right_on = 'CO_TAZID' , how = 'inner')\n",
    "\n",
    "# Show first 5 rows of merged table\n",
    "print(ato_table.head())\n",
    "print()\n",
    "\n",
    "print(ato_table.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store output folder path. There is a hidden .gitignore file here so files written won't be pushed to github\n",
    "temp = os.path.join(os.getcwd(), 'Results')\n",
    "\n",
    "# Create name for output csv\n",
    "out_table = os.path.join(temp, 'ATO.csv')\n",
    "\n",
    "# export data frame to csv\n",
    "ato_table.to_csv(out_table, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final step would be joining the output table to a TAZ shapefile/feature dataset using ArcGIS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
